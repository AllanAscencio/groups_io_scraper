{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.18.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: trio~=0.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 python-dotenv selenium pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "class GroupsIOScraper:\n",
    "    def __init__(self):\n",
    "        self.session = requests.Session()\n",
    "        self.base_url = \"https://groups.io\"\n",
    "        self.login_url = f\"{self.base_url}/login\"\n",
    "        self.driver = None\n",
    "        \n",
    "    def login_with_requests(self, email, password):\n",
    "        \"\"\"Attempt to login using requests library\"\"\"\n",
    "        try:\n",
    "            # Get the login page first to obtain CSRF token\n",
    "            response = self.session.get(self.login_url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract CSRF token\n",
    "            csrf_token = soup.find('input', {'name': 'csrf'})['value']\n",
    "            monocle_token = soup.find('input', {'name': 'monocle'})['value']\n",
    "            \n",
    "            # Prepare login data\n",
    "            login_data = {\n",
    "                'email': email,\n",
    "                'password': password,\n",
    "                'csrf': csrf_token,\n",
    "                'monocle': monocle_token,\n",
    "                'timezone': 'America/New_York'\n",
    "            }\n",
    "            \n",
    "            # Attempt login\n",
    "            response = self.session.post(self.login_url, data=login_data)\n",
    "            \n",
    "            # Check if login was successful\n",
    "            if response.url != self.login_url:  # Usually redirects after successful login\n",
    "                print(\"Login successful using requests!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Login failed using requests, trying Selenium...\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during requests login: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def login_with_selenium(self, email, password):\n",
    "        \"\"\"Attempt to login using Selenium\"\"\"\n",
    "        try:\n",
    "            # Initialize Chrome driver if not already initialized\n",
    "            if self.driver is None:\n",
    "                self.driver = webdriver.Chrome()\n",
    "            \n",
    "            self.driver.get(self.login_url)\n",
    "            \n",
    "            # Wait for email field and enter credentials\n",
    "            email_field = WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.ID, \"email\"))\n",
    "            )\n",
    "            email_field.send_keys(email)\n",
    "            \n",
    "            # Find and fill password field\n",
    "            password_field = self.driver.find_element(By.ID, \"password\")\n",
    "            password_field.send_keys(password)\n",
    "            \n",
    "            # Click login button\n",
    "            login_button = self.driver.find_element(By.ID, \"loginbutton\")\n",
    "            login_button.click()\n",
    "            \n",
    "            # Wait for redirect or new element that indicates successful login\n",
    "            time.sleep(3)  # Give it some time to process\n",
    "            \n",
    "            # Check if login was successful\n",
    "            if self.driver.current_url != self.login_url:\n",
    "                print(\"Login successful using Selenium!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Login failed using Selenium\")\n",
    "                self.quit_driver()\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during Selenium login: {str(e)}\")\n",
    "            self.quit_driver()\n",
    "            return False\n",
    "    \n",
    "    def quit_driver(self):\n",
    "        \"\"\"Safely quit the Selenium driver\"\"\"\n",
    "        if self.driver is not None:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "    \n",
    "    def get_driver(self):\n",
    "        \"\"\"Return the current driver instance\"\"\"\n",
    "        return self.driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscraper = GroupsIOScraper()\\nif scraper.login_with_selenium(email, password):\\n    forum_scraper = GroupsIOForumScraper(scraper.get_driver())\\n    posts, replies = forum_scraper.scrape_forum(max_pages=5)\\n    forum_scraper.save_to_csv()\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "class GroupsIOForumScraper:\n",
    "    def __init__(self, driver):\n",
    "        \"\"\"Initialize with Selenium webdriver instance\"\"\"\n",
    "        self.driver = driver\n",
    "        self.base_url = \"https://groups.io/g/peds-endo\"\n",
    "        self.posts_data = []\n",
    "        self.replies_data = []\n",
    "        \n",
    "    def navigate_to_topics(self):\n",
    "        \"\"\"Navigate to the topics page\"\"\"\n",
    "        try:\n",
    "            topics_url = f\"{self.base_url}/topics\"\n",
    "            self.driver.get(topics_url)\n",
    "            time.sleep(3)  # Wait for page to load\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error navigating to topics page: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def get_next_page_url(self):\n",
    "        \"\"\"Extract the URL for the next page\"\"\"\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        pagination = soup.find('ul', {'class': 'pagination'})\n",
    "        if pagination:\n",
    "            next_link = pagination.find('a', href=lambda x: x and 'page=' in x)\n",
    "            if next_link:\n",
    "                # Return complete URL\n",
    "                return f\"https://groups.io{next_link['href']}\" if next_link['href'].startswith('/') else next_link['href']\n",
    "        return None\n",
    "\n",
    "    def collect_all_preview_data(self, max_pages=None):\n",
    "        \"\"\"Collect preview data from all pages before processing individual posts\"\"\"\n",
    "        print(\"Starting to collect preview data from all pages...\")\n",
    "        all_preview_data = []\n",
    "        current_page = 1\n",
    "        \n",
    "        while True:\n",
    "            print(f\"Collecting previews from page {current_page}...\")\n",
    "            \n",
    "            # Scrape current page\n",
    "            page_topics = self.scrape_topics_page()\n",
    "            all_preview_data.extend(page_topics)\n",
    "            \n",
    "            # Check if we've reached max_pages\n",
    "            if max_pages and current_page >= max_pages:\n",
    "                print(f\"Reached maximum pages limit ({max_pages})\")\n",
    "                break\n",
    "            \n",
    "            # Move to next page using simple page numbering\n",
    "            current_page += 1\n",
    "            if current_page == 2:  # First page change\n",
    "                next_url = f\"https://groups.io/g/peds-endo/topics?page={current_page}\"\n",
    "                self.driver.get(next_url)\n",
    "                time.sleep(3)\n",
    "            elif current_page > 2:  # Subsequent pages\n",
    "                # Just change the page number in the URL\n",
    "                next_url = f\"https://groups.io/g/peds-endo/topics?page={current_page}\"\n",
    "                self.driver.get(next_url)\n",
    "                time.sleep(3)\n",
    "            \n",
    "        print(f\"Collected preview data for {len(all_preview_data)} topics\")\n",
    "        return all_preview_data\n",
    "\n",
    "    def process_posts_with_replies(self, preview_data):\n",
    "        \"\"\"Process individual posts that have replies\"\"\"\n",
    "        print(\"Starting to process individual posts with replies...\")\n",
    "        \n",
    "        for topic in preview_data:\n",
    "            if topic['reply_count'] > 0:\n",
    "                print(f\"Processing post: {topic['title']} (Reply count: {topic['reply_count']})\")\n",
    "                self.scrape_single_post(topic['url'], topic.copy())\n",
    "            else:\n",
    "                # For posts without replies, just add the preview data\n",
    "                topic['post_id'] = self.extract_post_id(topic['url'])\n",
    "                topic['full_content'] = topic['preview']\n",
    "                self.posts_data.append(topic)\n",
    "\n",
    "    def scrape_topics_page(self):\n",
    "        \"\"\"Scrape all topics from the current page\"\"\"\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        topics = []\n",
    "        \n",
    "        # Find all topic rows in the table\n",
    "        topic_rows = soup.find('table', {'id': 'records'}).find_all('tr')\n",
    "        \n",
    "        for row in topic_rows:\n",
    "            topic_data = self._parse_topic_row(row)\n",
    "            if topic_data:\n",
    "                topics.append(topic_data)\n",
    "                \n",
    "        return topics\n",
    "    \n",
    "    def _parse_topic_row(self, row):\n",
    "        \"\"\"Parse individual topic row\"\"\"\n",
    "        try:\n",
    "            # Main container for topic info\n",
    "            topic_container = row.find('div', {'style': 'margin-top:3px;margin-bottom:3px;'})\n",
    "            if not topic_container:\n",
    "                return None\n",
    "                \n",
    "            # Get topic link and title\n",
    "            subject_span = topic_container.find('span', {'class': 'subject'})\n",
    "            if not subject_span:\n",
    "                return None\n",
    "                \n",
    "            link = subject_span.find('a')\n",
    "            topic_url = link['href'] if link else None\n",
    "            topic_title = link.text.strip() if link else None\n",
    "            \n",
    "            # Get topic preview\n",
    "            preview_div = topic_container.find('div', {'class': 'truncate-one-line'})\n",
    "            preview_text = preview_div.text.strip() if preview_div else None\n",
    "            \n",
    "            # Get thread info (author, dates)\n",
    "            thread_info = topic_container.find('span', {'class': 'thread-attribution'})\n",
    "            author = thread_info.find(string=True, recursive=False).strip().replace('Started by', '').strip() if thread_info else None\n",
    "            \n",
    "            # Get dates\n",
    "            dates = thread_info.find_all('span', {'title': True})\n",
    "            start_date = dates[0]['title'] if dates else None\n",
    "            last_reply_date = dates[1]['title'] if len(dates) > 1 else None\n",
    "            \n",
    "            # Get reply count\n",
    "            reply_count = 0\n",
    "            hashtag_span = subject_span.find('span', {'class': 'hashtag-position'})\n",
    "            if hashtag_span:\n",
    "                try:\n",
    "                    reply_count = int(hashtag_span.text.strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                    \n",
    "            # Get if attachments exist\n",
    "            has_attachments = bool(subject_span.find('i', {'class': 'fa-paperclip'}))\n",
    "            \n",
    "            return {\n",
    "                'title': topic_title,\n",
    "                'url': topic_url,\n",
    "                'preview': preview_text,\n",
    "                'author': author,\n",
    "                'start_date': start_date,\n",
    "                'last_reply_date': last_reply_date,\n",
    "                'reply_count': reply_count,\n",
    "                'has_attachments': has_attachments\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing row: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def extract_post_id(self, url):\n",
    "        \"\"\"Extract post ID from URL\"\"\"\n",
    "        try:\n",
    "            return url.split('/')[-1]\n",
    "        except:\n",
    "            return None\n",
    "            \n",
    "    def parse_date(self, date_str):\n",
    "        \"\"\"Parse date string into standardized format\"\"\"\n",
    "        try:\n",
    "            # Add your date parsing logic here\n",
    "            return date_str\n",
    "        except:\n",
    "            return None\n",
    "            \n",
    "    def scrape_single_post(self, url, topic_data):\n",
    "        \"\"\"Scrape an individual post and its replies\"\"\"\n",
    "        try:\n",
    "            # Navigate to post page\n",
    "            self.driver.get(url)\n",
    "            time.sleep(2)\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Extract main post content\n",
    "            main_post = soup.find('div', {'class': 'table-background-color expanded-message'})\n",
    "            if not main_post:\n",
    "                return\n",
    "                \n",
    "            # Get main post details\n",
    "            post_id = self.extract_post_id(url)\n",
    "            author = main_post.find('u').text.strip() if main_post.find('u') else None\n",
    "            date = main_post.find('span', {'title': True})['title'] if main_post.find('span', {'title': True}) else None\n",
    "            content = main_post.find('div', {'id': lambda x: x and x.startswith('msgbody')}).text.strip() if main_post.find('div', {'id': lambda x: x and x.startswith('msgbody')}) else None\n",
    "            \n",
    "            # Update the topic data with full content\n",
    "            topic_data.update({\n",
    "                'post_id': post_id,\n",
    "                'full_content': content,\n",
    "                'author': author,\n",
    "                'date': self.parse_date(date)\n",
    "            })\n",
    "            self.posts_data.append(topic_data)\n",
    "            \n",
    "            # Get replies (all subsequent expanded-message divs)\n",
    "            replies = soup.find_all('div', {'class': 'table-background-color expanded-message'})[1:]  # Skip first one (main post)\n",
    "            \n",
    "            for reply in replies:\n",
    "                reply_data = {\n",
    "                    'parent_post_id': post_id,\n",
    "                    'reply_author': reply.find('u').text.strip() if reply.find('u') else None,\n",
    "                    'reply_date': self.parse_date(reply.find('span', {'title': True})['title']) if reply.find('span', {'title': True}) else None,\n",
    "                    'reply_content': reply.find('div', {'id': lambda x: x and x.startswith('msgbody')}).text.strip() if reply.find('div', {'id': lambda x: x and x.startswith('msgbody')}) else None\n",
    "                }\n",
    "                self.replies_data.append(reply_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping post {url}: {str(e)}\")\n",
    "            \n",
    "    def scrape_forum(self, max_pages=None):\n",
    "        \"\"\"Main method to scrape the forum\"\"\"\n",
    "        if not self.navigate_to_topics():\n",
    "            return False\n",
    "            \n",
    "        # First collect all preview data\n",
    "        preview_data = self.collect_all_preview_data(max_pages)\n",
    "        \n",
    "        # Then process posts with replies\n",
    "        self.process_posts_with_replies(preview_data)\n",
    "        \n",
    "        return self.posts_data, self.replies_data\n",
    "            \n",
    "    def save_to_csv(self, posts_filename='posts.csv', replies_filename='replies.csv'):\n",
    "        \"\"\"Save posts and replies to separate CSV files\"\"\"\n",
    "        # Save posts\n",
    "        posts_df = pd.DataFrame(self.posts_data)\n",
    "        posts_df.to_csv(posts_filename, index=False)\n",
    "        print(f\"Saved {len(self.posts_data)} posts to {posts_filename}\")\n",
    "        \n",
    "        # Save replies\n",
    "        replies_df = pd.DataFrame(self.replies_data)\n",
    "        replies_df.to_csv(replies_filename, index=False)\n",
    "        print(f\"Saved {len(self.replies_data)} replies to {replies_filename}\")\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "scraper = GroupsIOScraper()\n",
    "if scraper.login_with_selenium(email, password):\n",
    "    forum_scraper = GroupsIOForumScraper(scraper.get_driver())\n",
    "    posts, replies = forum_scraper.scrape_forum(max_pages=5)\n",
    "    forum_scraper.save_to_csv()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during requests login: 'NoneType' object is not subscriptable\n",
      "Login successful using Selenium!\n"
     ]
    }
   ],
   "source": [
    "scraper = GroupsIOScraper()\n",
    "email = \"allan.ascencio@gmail.com\"\n",
    "password = \"Sah%b5BGn9TBgia\"\n",
    "\n",
    "# Try requests first, then Selenium if needed\n",
    "if not scraper.login_with_requests(email, password):\n",
    "    selenium_success = scraper.login_with_selenium(email, password)\n",
    "    if not selenium_success:\n",
    "        print(\"All login attempts failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Use the driver for other operations\n",
    "driver = scraper.get_driver()\n",
    "if driver:\n",
    "    # Use the driver for additional operations\n",
    "    driver.get(\"https://groups.io/g/peds-endo/topics\")\n",
    "    # ... perform other operations ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful using Selenium!\n",
      "Starting to collect preview data from all pages...\n",
      "Collecting previews from page 1...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&after=1733530647300743547\n",
      "Collecting previews from page 2...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 3...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 4...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 5...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 6...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 7...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 8...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 9...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 10...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 11...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 12...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 13...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 14...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 15...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 16...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 17...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 18...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 19...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 20...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 21...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 22...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 23...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 24...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 25...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 26...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 27...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 28...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 29...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 30...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 31...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 32...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 33...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 34...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 35...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 36...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 37...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 38...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 39...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 40...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 41...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 42...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 43...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 44...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 45...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 46...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 47...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 48...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 49...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 50...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 51...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 52...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 53...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 54...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 55...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 56...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 57...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 58...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 59...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 60...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 61...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 62...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 63...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 64...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 65...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 66...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 67...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 68...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 69...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 70...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 71...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 72...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 73...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 74...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 75...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 76...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 77...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 78...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 79...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 80...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 81...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 82...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 83...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 84...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 85...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 86...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 87...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 88...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 89...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 90...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 91...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 92...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 93...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 94...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 95...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 96...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 97...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 98...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 99...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 100...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 101...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 102...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 103...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 104...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 105...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 106...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 107...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 108...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 109...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 110...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 111...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 112...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 113...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 114...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 115...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 116...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 117...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 118...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 119...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 120...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 121...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 122...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 123...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 124...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 125...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 126...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 127...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 128...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 129...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 130...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 131...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 132...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 133...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 134...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 135...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 136...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 137...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 138...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 139...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 140...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 141...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 142...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 143...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 144...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 145...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 146...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 147...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 148...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=3&after=1731481815837865745\n",
      "Collecting previews from page 149...\n",
      "Navigating to next page: https://groups.io/g/peds-endo/topics?page=2&before=1731366218515591380\n",
      "Collecting previews from page 150...\n",
      "Reached maximum pages limit (150)\n",
      "Collected preview data for 3000 topics\n",
      "Starting to process individual posts with replies...\n",
      "Processing post: Ped Endo in Orlando, FL (Reply count: 2)\n",
      "Processing post: Hypercalcemia Case (Reply count: 8)\n",
      "Processing post: Thyroid- DIO2 rs225014 homozygous genotype (Reply count: 3)\n",
      "Processing post: Ped Endo in Austin TX and Valdosta GA (Reply count: 5)\n",
      "Processing post: Metabolic bone disease (Reply count: 4)\n",
      "Processing post: POI and elevated DHEAS (Reply count: 13)\n",
      "Processing post: levothyroxine absorption test (Reply count: 5)\n",
      "Processing post: NR5A1 mutation experience (Reply count: 7)\n",
      "Processing post: RD/CDCES vs RN/CDCES - Salary Question (Reply count: 2)\n",
      "Processing post: interesting case of elevated testosterone (Reply count: 4)\n",
      "Processing post: MEN-1 and small hepatic lesion (Reply count: 12)\n",
      "Processing post: Adrenal recovery after treatment with mitotane? (Reply count: 2)\n",
      "Processing post: Primary autoimmune adrenocortical insufficy expertise needed (Reply count: 3)\n",
      "Processing post: - Re: [peds-endo] Stage 1 type 1 diabetes (Reply count: 3)\n",
      "Processing post: Stage 1 type 1 diabetes (Reply count: 2)\n",
      "Processing post: patient with T1DM moving to New Zealan (Reply count: 2)\n",
      "Processing post: Two open fellowship positions at Lurie Children's Hospital of Chicago (Reply count: 2)\n",
      "Processing post: Difficult case of hypoglycemia in a kid with Trisomy 21 (Reply count: 16)\n",
      "Processing post: Ped Endo in Rio (Reply count: 2)\n",
      "Processing post: Dose of desmopressin for IPSS (Reply count: 3)\n",
      "Processing post: androgen insensitivity syndrome and craniosynostosis (Reply count: 4)\n",
      "Processing post: A Thanksgiving Message of Gratitude (Reply count: 2)\n",
      "Processing post: Bisphosphonate for Pain Relief in Metastatic Bone CA (Reply count: 3)\n",
      "Processing post: Follow up on a previous case of hypercalcemia (Reply count: 2)\n",
      "Processing post: Alstrom syndrome (Reply count: 2)\n",
      "Processing post: case : puberty (Reply count: 8)\n",
      "Processing post: - Re: [peds-endo] [case] Cushing Syndrome....no really...I think I found one! (Reply count: 4)\n",
      "Processing post: [case] Cushing Syndrome....no really...I think I found one! (Reply count: 6)\n",
      "Processing post: - [peds-endo] case : puberty (Reply count: 4)\n",
      "Processing post: Reminder: Growth hormone and brain MRI survey (Reply count: 2)\n",
      "Processing post: Panhypopituitarism secondary to craniopharyngioma resection (Reply count: 3)\n",
      "Processing post: Peds Endo near Talcahuano Chile (Reply count: 2)\n",
      "Processing post: treatment of tall stature in Weaver Syndrome (Reply count: 3)\n",
      "Processing post: SEMA3A mutation (Reply count: 4)\n",
      "Processing post: Question about Bicalutamide use in precocious puberty (Reply count: 4)\n",
      "Processing post: Case - recent change in responses to growth hormone and hCG (Reply count: 2)\n",
      "Processing post: Peds Endo positions (Reply count: 3)\n",
      "Processing post: Pedi endocrinologist at Nemours? (Reply count: 5)\n",
      "Processing post: - Re: [peds-endo] Stage 1 type 1 diabetes (Reply count: 3)\n",
      "Processing post: Stage 1 type 1 diabetes (Reply count: 2)\n",
      "Processing post: patient with T1DM moving to New Zealan (Reply count: 2)\n",
      "Processing post: Two open fellowship positions at Lurie Children's Hospital of Chicago (Reply count: 2)\n",
      "Processing post: Difficult case of hypoglycemia in a kid with Trisomy 21 (Reply count: 16)\n",
      "Processing post: Ped Endo in Rio (Reply count: 2)\n",
      "Processing post: Dose of desmopressin for IPSS (Reply count: 3)\n",
      "Processing post: androgen insensitivity syndrome and craniosynostosis (Reply count: 4)\n",
      "Processing post: A Thanksgiving Message of Gratitude (Reply count: 2)\n",
      "Processing post: Bisphosphonate for Pain Relief in Metastatic Bone CA (Reply count: 3)\n",
      "Processing post: Follow up on a previous case of hypercalcemia (Reply count: 2)\n",
      "Processing post: Alstrom syndrome (Reply count: 2)\n",
      "Processing post: case : puberty (Reply count: 8)\n",
      "Processing post: - Re: [peds-endo] [case] Cushing Syndrome....no really...I think I found one! (Reply count: 4)\n",
      "Processing post: [case] Cushing Syndrome....no really...I think I found one! (Reply count: 6)\n",
      "Processing post: - [peds-endo] case : puberty (Reply count: 4)\n",
      "Processing post: Reminder: Growth hormone and brain MRI survey (Reply count: 2)\n",
      "Processing post: Panhypopituitarism secondary to craniopharyngioma resection (Reply count: 3)\n",
      "Processing post: Peds Endo near Talcahuano Chile (Reply count: 2)\n",
      "Processing post: treatment of tall stature in Weaver Syndrome (Reply count: 3)\n",
      "Processing post: SEMA3A mutation (Reply count: 4)\n",
      "Processing post: Question about Bicalutamide use in precocious puberty (Reply count: 4)\n",
      "Processing post: Case - recent change in responses to growth hormone and hCG (Reply count: 2)\n",
      "Processing post: Peds Endo positions (Reply count: 3)\n",
      "Processing post: Pedi endocrinologist at Nemours? (Reply count: 5)\n",
      "Processing post: - Re: [peds-endo] Stage 1 type 1 diabetes (Reply count: 3)\n",
      "Processing post: Stage 1 type 1 diabetes (Reply count: 2)\n",
      "Processing post: patient with T1DM moving to New Zealan (Reply count: 2)\n",
      "Processing post: Two open fellowship positions at Lurie Children's Hospital of Chicago (Reply count: 2)\n",
      "Processing post: Difficult case of hypoglycemia in a kid with Trisomy 21 (Reply count: 16)\n",
      "Processing post: Ped Endo in Rio (Reply count: 2)\n",
      "Processing post: Dose of desmopressin for IPSS (Reply count: 3)\n",
      "Processing post: androgen insensitivity syndrome and craniosynostosis (Reply count: 4)\n",
      "Processing post: A Thanksgiving Message of Gratitude (Reply count: 2)\n",
      "Processing post: Bisphosphonate for Pain Relief in Metastatic Bone CA (Reply count: 3)\n",
      "Processing post: Follow up on a previous case of hypercalcemia (Reply count: 2)\n",
      "Processing post: Alstrom syndrome (Reply count: 2)\n",
      "Processing post: case : puberty (Reply count: 8)\n",
      "Processing post: - Re: [peds-endo] [case] Cushing Syndrome....no really...I think I found one! (Reply count: 4)\n",
      "Processing post: [case] Cushing Syndrome....no really...I think I found one! (Reply count: 6)\n",
      "Processing post: - [peds-endo] case : puberty (Reply count: 4)\n",
      "Processing post: Reminder: Growth hormone and brain MRI survey (Reply count: 2)\n",
      "Processing post: Panhypopituitarism secondary to craniopharyngioma resection (Reply count: 3)\n",
      "Processing post: Peds Endo near Talcahuano Chile (Reply count: 2)\n",
      "Processing post: treatment of tall stature in Weaver Syndrome (Reply count: 3)\n",
      "Processing post: SEMA3A mutation (Reply count: 4)\n",
      "Processing post: Question about Bicalutamide use in precocious puberty (Reply count: 4)\n",
      "Processing post: Case - recent change in responses to growth hormone and hCG (Reply count: 2)\n",
      "Processing post: Peds Endo positions (Reply count: 3)\n",
      "Processing post: Pedi endocrinologist at Nemours? (Reply count: 5)\n",
      "Processing post: - Re: [peds-endo] Stage 1 type 1 diabetes (Reply count: 3)\n",
      "Processing post: Stage 1 type 1 diabetes (Reply count: 2)\n",
      "Processing post: patient with T1DM moving to New Zealan (Reply count: 2)\n",
      "Processing post: Two open fellowship positions at Lurie Children's Hospital of Chicago (Reply count: 2)\n",
      "Processing post: Difficult case of hypoglycemia in a kid with Trisomy 21 (Reply count: 16)\n",
      "Processing post: Ped Endo in Rio (Reply count: 2)\n",
      "Processing post: Dose of desmopressin for IPSS (Reply count: 3)\n",
      "Processing post: androgen insensitivity syndrome and craniosynostosis (Reply count: 4)\n",
      "Processing post: A Thanksgiving Message of Gratitude (Reply count: 2)\n",
      "Processing post: Bisphosphonate for Pain Relief in Metastatic Bone CA (Reply count: 3)\n",
      "Processing post: Follow up on a previous case of hypercalcemia (Reply count: 2)\n",
      "Processing post: Alstrom syndrome (Reply count: 2)\n",
      "Processing post: case : puberty (Reply count: 8)\n",
      "Processing post: - Re: [peds-endo] [case] Cushing Syndrome....no really...I think I found one! (Reply count: 4)\n",
      "Processing post: [case] Cushing Syndrome....no really...I think I found one! (Reply count: 6)\n",
      "Processing post: - [peds-endo] case : puberty (Reply count: 4)\n",
      "Processing post: Reminder: Growth hormone and brain MRI survey (Reply count: 2)\n",
      "Processing post: Panhypopituitarism secondary to craniopharyngioma resection (Reply count: 3)\n",
      "Processing post: Peds Endo near Talcahuano Chile (Reply count: 2)\n",
      "Processing post: treatment of tall stature in Weaver Syndrome (Reply count: 3)\n",
      "Processing post: SEMA3A mutation (Reply count: 4)\n",
      "Processing post: Question about Bicalutamide use in precocious puberty (Reply count: 4)\n",
      "Processing post: Case - recent change in responses to growth hormone and hCG (Reply count: 2)\n",
      "Processing post: Peds Endo positions (Reply count: 3)\n",
      "Processing post: Pedi endocrinologist at Nemours? (Reply count: 5)\n",
      "Processing post: - Re: [peds-endo] Stage 1 type 1 diabetes (Reply count: 3)\n",
      "Processing post: Stage 1 type 1 diabetes (Reply count: 2)\n",
      "Processing post: patient with T1DM moving to New Zealan (Reply count: 2)\n",
      "Processing post: Two open fellowship positions at Lurie Children's Hospital of Chicago (Reply count: 2)\n",
      "Processing post: Difficult case of hypoglycemia in a kid with Trisomy 21 (Reply count: 16)\n",
      "Processing post: Ped Endo in Rio (Reply count: 2)\n",
      "Processing post: Dose of desmopressin for IPSS (Reply count: 3)\n",
      "Processing post: androgen insensitivity syndrome and craniosynostosis (Reply count: 4)\n",
      "Processing post: A Thanksgiving Message of Gratitude (Reply count: 2)\n",
      "Processing post: Bisphosphonate for Pain Relief in Metastatic Bone CA (Reply count: 3)\n",
      "Processing post: Follow up on a previous case of hypercalcemia (Reply count: 2)\n",
      "Processing post: Alstrom syndrome (Reply count: 2)\n",
      "Processing post: case : puberty (Reply count: 8)\n",
      "Processing post: - Re: [peds-endo] [case] Cushing Syndrome....no really...I think I found one! (Reply count: 4)\n",
      "Processing post: [case] Cushing Syndrome....no really...I think I found one! (Reply count: 6)\n",
      "Processing post: - [peds-endo] case : puberty (Reply count: 4)\n",
      "Processing post: Reminder: Growth hormone and brain MRI survey (Reply count: 2)\n",
      "Processing post: Panhypopituitarism secondary to craniopharyngioma resection (Reply count: 3)\n",
      "Processing post: Peds Endo near Talcahuano Chile (Reply count: 2)\n",
      "Processing post: treatment of tall stature in Weaver Syndrome (Reply count: 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scraper\u001b[38;5;241m.\u001b[39mlogin_with_selenium(email, password):\n\u001b[1;32m      3\u001b[0m     forum_scraper \u001b[38;5;241m=\u001b[39m GroupsIOForumScraper(scraper\u001b[38;5;241m.\u001b[39mget_driver())\n\u001b[0;32m----> 4\u001b[0m     posts, replies \u001b[38;5;241m=\u001b[39m \u001b[43mforum_scraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_forum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     forum_scraper\u001b[38;5;241m.\u001b[39msave_to_csv()\n",
      "Cell \u001b[0;32mIn[24], line 223\u001b[0m, in \u001b[0;36mGroupsIOForumScraper.scrape_forum\u001b[0;34m(self, max_pages)\u001b[0m\n\u001b[1;32m    220\u001b[0m preview_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect_all_preview_data(max_pages)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Then process posts with replies\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_posts_with_replies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreview_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposts_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplies_data\n",
      "Cell \u001b[0;32mIn[24], line 77\u001b[0m, in \u001b[0;36mGroupsIOForumScraper.process_posts_with_replies\u001b[0;34m(self, preview_data)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreply_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing post: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Reply count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreply_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_single_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# For posts without replies, just add the preview data\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     topic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_post_id(topic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[24], line 175\u001b[0m, in \u001b[0;36mGroupsIOForumScraper.scrape_single_post\u001b[0;34m(self, url, topic_data)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scrape an individual post and its replies\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Navigate to post page\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    177\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/_request_methods.py:118\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    111\u001b[0m         method,\n\u001b[1;32m    112\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/_request_methods.py:217\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    213\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    215\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scraper = GroupsIOScraper()\n",
    "if scraper.login_with_selenium(email, password):\n",
    "    forum_scraper = GroupsIOForumScraper(scraper.get_driver())\n",
    "    posts, replies = forum_scraper.scrape_forum(max_pages=150)\n",
    "    forum_scraper.save_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Clean up when done\n",
    "scraper.quit_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
